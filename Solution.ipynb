{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "alpha-message",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-basement",
   "metadata": {},
   "source": [
    "## The goals / steps of this project are the following:\n",
    "\n",
    "1. Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "2. Apply a distortion correction to raw images.\n",
    "3. Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "4. Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "5. Detect lane pixels and fit to find the lane boundary.\n",
    "6. Determine the curvature of the lane and vehicle position with respect to center.\n",
    "7. Warp the detected lane boundaries back onto the original image.\n",
    "8. Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-polyester",
   "metadata": {},
   "source": [
    "### First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-malta",
   "metadata": {},
   "source": [
    "## Stages\n",
    "\n",
    "1. Preprocessing\n",
    "2. Algorithm\n",
    "3. Vaidation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-madison",
   "metadata": {},
   "source": [
    "### 1. Preprocessing\n",
    "\n",
    "1. Compute the camera calibration.\n",
    "2. Compute the camera distortion paramters.\n",
    "3. Undistort the camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-contrast",
   "metadata": {},
   "source": [
    "The used chessboard is 9x6 grid\n",
    "`Some images are not valid`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 9\n",
    "ny = 6\n",
    "\n",
    "objp = np.zeros((ny*nx,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-assignment",
   "metadata": {},
   "source": [
    "I used `cv2.cornerSubPix` which generate more accurate corner positions. Still, not diff appear on corners values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all calibartion images\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "calibration_images = glob.glob('camera_cal/*.jpg')\n",
    "for image in calibration_images:\n",
    "    calb_image = mpimg.imread(image)\n",
    "    gray_image = cv2.cvtColor(calb_image, cv2.COLOR_RGB2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(calb_image, (nx, ny), None)\n",
    "    if(ret == True):\n",
    "        objpoints.append(objp)\n",
    "        corner_image = np.copy(calb_image)\n",
    "        # corners2 = cv2.cornerSubPix(gray_image, corners, (11,11), (-1,-1), criteria)\n",
    "        # print(np.sum(corners - corners2))\n",
    "        imgpoints.append(corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray_image.shape[::-1], None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-heart",
   "metadata": {},
   "source": [
    "I select `calibration1,calibration5` because the radial distortion is easy to notice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-pursuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in ['camera_cal/calibration1.jpg', 'camera_cal/calibration5.jpg']:\n",
    "    test_image = cv2.imread(image)\n",
    "    h,  w = test_image.shape[:2]\n",
    "    undistorted_image = cv2.undistort(test_image, mtx, dist, None)\n",
    "\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(test_image)\n",
    "    ax1.set_title('Original Image', fontsize=50)\n",
    "    ax2.imshow(undistorted_image)\n",
    "    ax2.set_title('Undistorted Image', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-approach",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
